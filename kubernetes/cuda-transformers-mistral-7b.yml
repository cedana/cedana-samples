apiVersion: v1
kind: Pod
metadata:
  generateName: transformers-mistral-7b-
  namespace: default
spec:
  runtimeClassName: cedana # required for GPU C/R support (use nvidia for native)
  containers:
    - name: transformers-mistral-7b
      image: cedana/cedana-samples:cuda12.4-torch2.5
      command:
        - python3
        - -u
        - /app/gpu_smr/pytorch/llm/transformers_inference.py
        - --readiness-port=8888
        - --model=mistralai/Mistral-7B-v0.1
      env:
        - name: HF_TOKEN
          value: <TOKEN>
      ports:
        - containerPort: 8888
      readinessProbe:
        tcpSocket:
          port: 8888
        initialDelaySeconds: 1
        periodSeconds: 1
        timeoutSeconds: 1
      resources:
        limits:
          nvidia.com/gpu: 1
