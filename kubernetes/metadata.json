[
  {
    "filename": "cpu/counting.yaml",
    "title": "Timestamp Logger",
    "description": "Continuously logs timestamps in a pod for manual checkpoint/restore testing.",
    "type": "cpu",
    "labels": ["timer"]
  },
  {
    "filename": "cpu/counting-deployment.yaml",
    "title": "Timestamp Logger (Deployment)",
    "description": "Continuously logs timestamps in a deployment for automatic restore testing.",
    "type": "cpu",
    "labels": ["logging", "timer", "deployment"]
  },
  {
    "filename": "cpu/counting-persistent-volume.yaml",
    "title": "Simple Counter (Persistent Volume)",
    "description": "Tests reading from a persistent volume for persistent volume checkpoint/restore testing.",
    "type": "cpu",
    "labels": ["counter", "storage", "persistent-volume"]
  },
  {
    "filename": "cpu/counting-multicontainer.yaml",
    "title": "Timestamp Logger (Multi-container)",
    "description": "Continuously logs timestamps in a multi-container pod for manual checkpoint/restore testing.",
    "type": "cpu",
    "labels": ["logging", "timer", "multicontainer"]
  },
  {
    "filename": "cpu/nginx-deployment.yaml",
    "title": "NGINX Server (Deployment)",
    "description": "NGINX deployment for automatic restore testing.",
    "type": "cpu",
    "labels": ["web", "server", "nginx"]
  },
  {
    "filename": "cpu/jupyter-notebook.yaml",
    "title": "Jupyter Notebook Server",
    "description": "Jupyter notebook server pod with token authentication for manual checkpoint/restore testing.",
    "type": "cpu",
    "labels": ["interactive", "jupyter", "data-science"]
  },
  {
    "filename": "gpu/cuda-vector-add.yaml",
    "title": "CUDA Vector Addition",
    "description": "Runs CUDA vector addition to test GPU checkpoint and restore.",
    "type": "gpu",
    "labels": ["cuda", "math", "compute"]
  },
  {
    "filename": "gpu/cuda-vector-add-multicontainer.yaml",
    "title": "CUDA Vector Addition (Multi-container)",
    "description": "Runs CUDA vector addition in a multi-container pod to test GPU checkpoint and restore.",
    "type": "gpu",
    "labels": ["cuda", "math", "multicontainer"]
  },
  {
    "filename": "gpu/cuda-mem-throughput.yaml",
    "title": "CUDA Memory Throughput",
    "description": "Measures CUDA memory throughput for GPU performance testing.",
    "type": "gpu",
    "labels": ["cuda", "benchmark", "memory"]
  },
  {
<<<<<<< HEAD
    "filename": "cuda-pytorch-train.yaml",
=======
    "filename": "gpu/cuda-gpu-train-simple.yaml",
>>>>>>> b30a705 (fix: yamls)
    "title": "Simple PyTorch Training",
    "description": "Simple PyTorch training job for GPU checkpoint and restore testing.",
    "type": "gpu",
    "labels": ["pytorch", "training", "ml"]
  },
  {
<<<<<<< HEAD
    "filename": "cuda-multigpu-pytorch-train.yaml",
    "title": "Simple PyTorch Training (Multi-GPU)",
    "description": "Simple PyTorch multi-GPU training job for GPU checkpoint and restore testing.",
    "type": "gpu",
    "labels": ["pytorch", "training", "ml", "multigpu"]
  },
  {
    "filename": "cuda-transformers-gpt2.yml",
=======
    "filename": "gpu/cuda-transformers-gpt2.yml",
>>>>>>> b30a705 (fix: yamls)
    "title": "GPT-2 Transformer Inference",
    "description": "GPT-2 inference server with a readiness probe for restore vs. cold start benchmarking.",
    "type": "gpu",
    "labels": ["transformers", "llm", "inference"]
  },
  {
    "filename": "gpu/cuda-transformers-gpt2-xl.yml",
    "title": "GPT-2 XL Transformer Inference",
    "description": "GPT-2 XL inference server with a readiness probe for restore vs. cold start benchmarking.",
    "type": "gpu",
    "labels": ["transformers", "llm", "inference", "large-model"]
  },
  {
    "filename": "gpu/cuda-transformers-mistral-7b.yml",
    "title": "Mistral 7B Inference",
    "description": "Mistral-7B inference server with a readiness probe for restore vs. cold start benchmarking.",
    "type": "gpu",
    "labels": ["transformers", "nlp", "inference", "mistral"]
  },
  {
    "filename": "gpu/cuda-transformers-stablelm.yml",
    "title": "StableLM Inference",
    "description": "StableLM 2-1.6B inference server with a readiness probe for restore vs. cold start benchmarking.",
    "type": "gpu",
    "labels": ["transformers", "llm", "inference", "stablelm"]
  },
  {
    "filename": "gpu/cuda-vllm-llama-8b.yaml",
    "title": "vLLM Llama 3.1 8B Inference",
    "description": "vLLM Llama 3.1 8B inference server with a readiness probe for restore vs. cold start benchmarking.",
    "type": "gpu",
    "labels": ["vllm", "llm", "inference", "transformers"]
  },
  {
    "filename": "gpu/cuda-tensorflow.yaml",
    "title": "Sample Tensorflow Training",
    "description": "Trains a simple model using Tensorflow MirroredStrategy on single or multiple GPUs.",
    "type": "gpu",
    "labels": ["tensorflow", "training", "ml"]
  },
  {
    "filename": "gpu/cuda-deepspeed-train.yaml",
    "title": "Sample DeepSpeed Training",
    "description": "Trains a simple DeepSpeed model with FP16 and ZeRO optimization on a GPU.",
    "type": "gpu",
    "labels": ["deepspeed", "training", "ml", "optimization"]
  },
  {
    "filename": "gpu/cuda-2xGPU-deepspeed-train.yaml",
    "title": "DeepSpeed 2-GPU Training",
    "description": "Trains a DeepSpeed model with FP16 and ZeRO optimization on 2 GPUs.",
    "type": "gpu",
    "labels": ["deepspeed", "training", "ml", "optimization", "multigpu"]
  },
  {
    "filename": "gpu/yuning.yaml",
    "title": "Caltech Virtual Tissue Model",
    "description": "Virtual Tissue Model deployment. Requires GPU for simulation.",
    "type": "gpu",
    "labels": ["simulation", "biophysics", "compbio"]
  },
  {
    "filename": "gpu/gromacs-simple-example.yaml",
    "title": "GROMACS Molecular Dynamics Simulation (2ns)",
    "description": "Runs a simple GROMACS molecular dynamics simulation on a GPU.",
    "type": "gpu",
    "labels": ["molecular-dynamics", "gromacs", "compbio"]
  },
  {
    "filename": "gpu/gromacs-complex-example.yaml",
    "title": "GROMACS Molecular Dynamics Simulation (1000ns)",
    "description": "Runs a complex EM → NVT → NPT → production → RMSD/RMSF GROMACS simulation on a GPU.",
    "type": "gpu",
    "labels": ["molecular-dynamics", "gromacs", "compbio"]
  },
  {
    "filename": "gpu/openmm.yaml",
    "title": "OpenMM SimulatePdb",
    "description": "Runs an OpenMM molecular dynamics simulation (simulatePdb) on a GPU.",
    "type": "gpu",
    "labels": ["molecular-dynamics", "openmm", "compbio"]
  },
  {
<<<<<<< HEAD
    "filename": "cuda-bindcraft.yaml",
    "title": "BindCraft Example",
    "description": "An open-source and automated pipeline for de novo protein binder design",
    "type": "gpu",
    "labels": ["bindcraft", "protein-design", "compbio"]
=======
    "filename": "gpu/cuda-pytorch-cifar100.yaml",
    "title": "PyTorch CIFAR-100 Training",
    "description": "Trains a ResNet model on CIFAR-100 dataset using PyTorch on a GPU.",
    "type": "gpu",
    "labels": ["pytorch", "training", "ml", "cifar"]
  },
  {
    "filename": "gpu/cuda-4xGPU-pytorch-cifar100.yaml",
    "title": "PyTorch CIFAR-100 4-GPU Training",
    "description": "Trains a ResNet model on CIFAR-100 dataset using PyTorch on 4 GPUs.",
    "type": "gpu",
    "labels": ["pytorch", "training", "ml", "cifar", "multigpu"]
  },
  {
    "filename": "gpu/cuda-llamafactory-sft.yaml",
    "title": "LlamaFactory SFT Training",
    "description": "Supervised fine-tuning using LlamaFactory on a GPU.",
    "type": "gpu",
    "labels": ["llm", "training", "ml", "llamafactory", "sft"]
  },
  {
    "filename": "gpu/cuda-llamafactory-lora-sft.yaml",
    "title": "LlamaFactory LoRA SFT Training",
    "description": "LoRA supervised fine-tuning of Llama 3 using LlamaFactory on a GPU.",
    "type": "gpu",
    "labels": ["llm", "training", "ml", "llamafactory", "lora", "sft"]
  },
  {
    "filename": "gpu/cuda-2xGPU-llamafactory-lora-sft.yaml",
    "title": "LlamaFactory LoRA SFT 2-GPU Training",
    "description": "LoRA supervised fine-tuning of Llama 3 using LlamaFactory on 2 GPUs.",
    "type": "gpu",
    "labels": ["llm", "training", "ml", "llamafactory", "lora", "sft", "multigpu"]
  },
  {
    "filename": "gpu/cuda-vllm-llama-3.1-8b.yaml",
    "title": "vLLM Llama 3.1 8B Inference",
    "description": "vLLM Llama 3.1 8B inference server with a readiness probe for restore vs. cold start benchmarking.",
    "type": "gpu",
    "labels": ["vllm", "llm", "inference", "llama"]
>>>>>>> b30a705 (fix: yamls)
  }
]
