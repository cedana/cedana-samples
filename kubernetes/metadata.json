[
  {
    "filename": "counting.yaml",
    "title": "Timestamp Logger",
    "description": "Continuously logs timestamps in a pod for manual checkpoint/restore testing.",
    "type": "cpu"
  },
  {
    "filename": "counting-deployment.yaml",
    "title": "Timestamp Logger (Deployment)",
    "description": "Continuously logs timestamps in a deployment for automatic restore testing.",
    "type": "cpu"
  },
  {
    "filename": "counting-persistent-volume.yaml",
    "title": "Simple Counter (Persistent Volume)",
    "description": "Tests reading from a persistent volume for persistent volume checkpoint/restore testing.",
    "type": "cpu"
  },
  {
    "filename": "counting-multicontainer.yaml",
    "title": "Timestamp Logger (Multi-container)",
    "description": "Continuously logs timestamps in a multi-container pod for manual checkpoint/restore testing.",
    "type": "cpu"
  },
  {
    "filename": "nginx.yaml",
    "title": "NGINX Server (Deployment)",
    "description": "NGINX deployment for automatic restore testing.",
    "type": "cpu"
  },
  {
    "filename": "jupyter-notebook.yaml",
    "title": "Jupyter Notebook Server",
    "description": "Jupyter notebook server pod with token authentication for manual checkpoint/restore testing.",
    "type": "cpu"
  },
  {
    "filename": "cuda-vector-add.yaml",
    "title": "CUDA Vector Addition",
    "description": "Runs CUDA vector addition to test GPU checkpoint and restore.",
    "type": "gpu"
  },
  {
    "filename": "cuda-vector-add-multicontainer.yaml",
    "title": "CUDA Vector Addition (Multi-container)",
    "description": "Runs CUDA vector addition in a multi-container pod to test GPU checkpoint and restore.",
    "type": "gpu"
  },
  {
    "filename": "cuda-mem-throughput.yaml",
    "title": "CUDA Memory Throughput",
    "description": "Measures CUDA memory throughput for GPU performance testing.",
    "type": "gpu"
  },
  {
    "filename": "cuda-gpu-train-simple.yaml",
    "title": "Simple PyTorch Training",
    "description": "Simple PyTorch training job for GPU checkpoint and restore testing.",
    "type": "gpu"
  },
  {
    "filename": "cuda-transformers-gpt2.yml",
    "title": "GPT-2 Transformer Inference",
    "description": "GPT-2 inference server with a readiness probe for restore vs. cold start benchmarking.",
    "type": "gpu"
  },
  {
    "filename": "cuda-transformers-gpt2-xl.yml",
    "title": "GPT-2 XL Transformer Inference",
    "description": "GPT-2 XL inference server with a readiness probe for restore vs. cold start benchmarking.",
    "type": "gpu"
  },
  {
    "filename": "cuda-transformers-mistral-7b.yml",
    "title": "Mistral 7B Inference",
    "description": "Mistral-7B inference server with a readiness probe for restore vs. cold start benchmarking.",
    "type": "gpu"
  },
  {
    "filename": "cuda-transformers-stablelm.yml",
    "title": "StableLM Inference",
    "description": "StableLM 2-1.6B inference server with a readiness probe for restore vs. cold start benchmarking.",
    "type": "gpu"
  },
  {
    "filename": "cuda-vllm-llama-8b.yaml",
    "title": "vLLM Llama 3.1 8B Inference",
    "description": "vLLM Llama 3.1 8B inference server with a readiness probe for restore vs. cold start benchmarking.",
    "type": "gpu"
  },
  {
    "filename": "cuda-tensorflow.yaml",
    "title": "Sample Tensorflow Training",
    "description": "Trains a simple model using Tensorflow MirroredStrategy on single or multiple GPUs.",
    "type": "gpu"
  },
  {
    "filename": "cuda-deepspeed-train.yaml",
    "title": "Sample DeepSpeed Training",
    "description": "Trains a simple DeepSpeed model with FP16 and ZeRO optimization on GPUs",
    "type": "gpu"
  },
  {
    "filename": "yuning.yaml",
    "title": "Caltech Virtual Tissue Model",
    "description": "Virtual Tissue Model deployment. Requires GPU for simulation.",
    "type": "gpu"
  }
]
